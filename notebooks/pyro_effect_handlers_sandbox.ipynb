{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637c1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim.multi import MixedMultiOptimizer\n",
    "from pyro import poutine\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524dabd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.8824, -0.1313,  1.0409]),\n",
       " tensor([0.4127, 0.3570, 3.0340]),\n",
       " tensor([1.0000, 1.1000, 1.2000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(args):\n",
    "  with pyro.plate('mini_batch',args['x3_obs'].shape[0]):\n",
    "    loc_prior = args['loc_prior']\n",
    "    x1 = pyro.sample('x1',dist.Normal(loc_prior,1))\n",
    "    x2 = pyro.sample('x2',dist.Normal(x1,1))\n",
    "    x3 = pyro.sample('x3',dist.Normal(x2,1), obs=args['x3_obs'])\n",
    "  return x1, x2, x3\n",
    "\n",
    "args={}\n",
    "args['loc_prior'] = tensor(1.)\n",
    "args['x3_obs'] = tensor([1., 1.1, 1.2])\n",
    "\n",
    "model(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f859f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyro.poutine.trace_struct.Trace at 0x10d90f810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = pyro.poutine.trace(model).get_trace(args)\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f60a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = pyro.poutine.trace_logger(model).get_trace(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a18bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = pyro.poutine.trace_logger(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b499ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tl.get_trace(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1679fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10., requires_grad=True) tensor(10., requires_grad=True) tensor([11.5285,  9.8527,  9.5337], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(10., requires_grad=True), tensor(10., requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "def guide(args):\n",
    "  x1_loc = pyro.param('x1_loc',tensor(10.))\n",
    "  x2_loc = pyro.param('x2_loc',tensor(10.))\n",
    "  with pyro.plate('mini_batch',args['x3_obs'].shape[0]):\n",
    "    x1_dist = dist.Normal(x1_loc,1)\n",
    "    x1 = pyro.sample('x1',x1_dist)\n",
    "    x2 = pyro.sample('x2',dist.Normal(x2_loc,1))\n",
    "    print(x1_loc,x1_dist.loc,x1)\n",
    "\n",
    "g_trace = pyro.poutine.trace(guide).get_trace(args)\n",
    "params = [g_trace.nodes[name][\"value\"].unconstrained() for name in g_trace.param_nodes] # value changes during training. need to recompute g_trace\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c98da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_trace(model,guide,args,model_condition_data={}):\n",
    "  \"\"\"\n",
    "  TODO: guide_traces['x1/x2_loc'] history not stored. only most recent value\n",
    "    also not stored in guide_traces[0].nodes['x1']['fn'].loc\n",
    "  \"\"\"\n",
    "  # http://pyro.ai/examples/effect_handlers.html#Example:-Variational-inference-with-a-Monte-Carlo-ELBO\n",
    "  conditioned_model = poutine.condition(model, data=model_condition_data) # https://docs.pyro.ai/en/stable/poutine.html#module-pyro.poutine.handlers\n",
    "  guide_trace = poutine.trace_logger(guide).get_trace(args)\n",
    "  model_trace = poutine.trace_logger(\n",
    "          poutine.replay(conditioned_model, trace=guide_trace)\n",
    "      ).get_trace(args)\n",
    "  p = model_trace.log_prob_sum() \n",
    "  q = guide_trace.log_prob_sum()\n",
    "  elbo = p - q\n",
    "  elbo_loss = -elbo\n",
    "  return elbo_loss, model_trace, guide_trace\n",
    "\n",
    "def train(model, guide, data):\n",
    "  adam = pyro.optim.Adam({'lr': 0.1})\n",
    "  sgd = pyro.optim.SGD({'lr': 0.01})\n",
    "  optim = MixedMultiOptimizer([(['x1_loc'], adam), (['x2_loc'], sgd)])\n",
    "  losses = []\n",
    "  model_traces = []\n",
    "  guide_traces = []\n",
    "  x1_locs = []\n",
    "  x2_locs = []\n",
    "  for batch in data:\n",
    "      # this poutine.trace will record all of the parameters that appear in the model and guide\n",
    "      # during the execution of monte_carlo_elbo\n",
    "      with poutine.trace() as param_capture:\n",
    "          # we use poutine.block here so that only parameters appear in the trace above\n",
    "          with poutine.block(hide_fn=lambda node: node[\"type\"] != \"param\"):\n",
    "              elbo_loss, model_trace, guide_trace = loss_and_trace(model, guide, batch, model_condition_data={})\n",
    "              losses.append(elbo_loss.item())\n",
    "              model_traces.append(model_trace)\n",
    "              guide_traces.append(guide_trace)\n",
    "              x1_locs.append(pyro.param('x1_loc').item())\n",
    "              x2_locs.append(pyro.param('x2_loc').item())\n",
    "      params = {name: site['value'].unconstrained()\n",
    "        for name, site in param_capture.trace.nodes.items()\n",
    "        if site['type'] == 'param'}\n",
    "      optim.step(elbo_loss, params)\n",
    "  return losses, model_traces, guide_traces, x1_locs, x2_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209918a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df33929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10., requires_grad=True) tensor(10., requires_grad=True) tensor([10.1091,  9.3309,  9.8076], grad_fn=<AddBackward0>)\n",
      "tensor(9.9000, requires_grad=True) tensor(9.9000, requires_grad=True) tensor([ 9.8543, 10.0657, 10.6622], grad_fn=<AddBackward0>)\n",
      "tensor(9.7999, requires_grad=True) tensor(9.7999, requires_grad=True) tensor([10.2894, 11.0416, 11.2399], grad_fn=<AddBackward0>)\n",
      "tensor(9.6995, requires_grad=True) tensor(9.6995, requires_grad=True) tensor([11.1328, 11.3302,  8.5887], grad_fn=<AddBackward0>)\n",
      "tensor(9.5991, requires_grad=True) tensor(9.5991, requires_grad=True) tensor([ 8.5364,  8.2282, 11.7881], grad_fn=<AddBackward0>)\n",
      "tensor(9.4989, requires_grad=True) tensor(9.4989, requires_grad=True) tensor([ 8.1829, 10.6106,  9.9618], grad_fn=<AddBackward0>)\n",
      "tensor(9.3985, requires_grad=True) tensor(9.3985, requires_grad=True) tensor([10.6386, 10.5825,  9.2441], grad_fn=<AddBackward0>)\n",
      "tensor(9.2979, requires_grad=True) tensor(9.2979, requires_grad=True) tensor([ 8.7102,  8.4640, 10.4760], grad_fn=<AddBackward0>)\n",
      "tensor(9.1985, requires_grad=True) tensor(9.1985, requires_grad=True) tensor([ 9.7782, 10.2795,  9.1400], grad_fn=<AddBackward0>)\n",
      "tensor(9.0988, requires_grad=True) tensor(9.0988, requires_grad=True) tensor([ 9.8434,  8.0866, 10.3881], grad_fn=<AddBackward0>)\n",
      "tensor(8.9992, requires_grad=True) tensor(8.9992, requires_grad=True) tensor([ 8.7601,  6.9656, 10.3292], grad_fn=<AddBackward0>)\n",
      "tensor(8.9003, requires_grad=True) tensor(8.9003, requires_grad=True) tensor([11.0573,  8.5765, 10.9433], grad_fn=<AddBackward0>)\n",
      "tensor(8.8004, requires_grad=True) tensor(8.8004, requires_grad=True) tensor([9.1728, 8.8848, 8.5709], grad_fn=<AddBackward0>)\n",
      "tensor(8.7005, requires_grad=True) tensor(8.7005, requires_grad=True) tensor([ 7.8769,  9.1463, 10.2275], grad_fn=<AddBackward0>)\n",
      "tensor(8.6009, requires_grad=True) tensor(8.6009, requires_grad=True) tensor([7.6006, 9.1169, 8.7249], grad_fn=<AddBackward0>)\n",
      "tensor(8.5023, requires_grad=True) tensor(8.5023, requires_grad=True) tensor([8.9823, 8.1102, 8.0294], grad_fn=<AddBackward0>)\n",
      "tensor(8.4038, requires_grad=True) tensor(8.4038, requires_grad=True) tensor([ 6.8775, 10.5501,  9.4776], grad_fn=<AddBackward0>)\n",
      "tensor(8.3053, requires_grad=True) tensor(8.3053, requires_grad=True) tensor([ 8.1112,  7.7297, 11.1280], grad_fn=<AddBackward0>)\n",
      "tensor(8.2066, requires_grad=True) tensor(8.2066, requires_grad=True) tensor([6.4257, 8.9222, 8.7694], grad_fn=<AddBackward0>)\n",
      "tensor(8.1091, requires_grad=True) tensor(8.1091, requires_grad=True) tensor([8.3889, 8.9537, 8.3833], grad_fn=<AddBackward0>)\n",
      "tensor(8.0112, requires_grad=True) tensor(8.0112, requires_grad=True) tensor([7.8738, 7.1376, 7.3101], grad_fn=<AddBackward0>)\n",
      "tensor(7.9137, requires_grad=True) tensor(7.9137, requires_grad=True) tensor([8.0955, 8.3216, 7.8903], grad_fn=<AddBackward0>)\n",
      "tensor(7.8159, requires_grad=True) tensor(7.8159, requires_grad=True) tensor([9.1537, 6.9463, 8.2730], grad_fn=<AddBackward0>)\n",
      "tensor(7.7179, requires_grad=True) tensor(7.7179, requires_grad=True) tensor([6.5700, 9.3949, 7.4937], grad_fn=<AddBackward0>)\n",
      "tensor(7.6202, requires_grad=True) tensor(7.6202, requires_grad=True) tensor([7.5337, 7.2172, 7.2186], grad_fn=<AddBackward0>)\n",
      "tensor(7.5231, requires_grad=True) tensor(7.5231, requires_grad=True) tensor([8.6440, 6.2849, 7.4194], grad_fn=<AddBackward0>)\n",
      "tensor(7.4260, requires_grad=True) tensor(7.4260, requires_grad=True) tensor([8.8152, 7.7187, 9.3382], grad_fn=<AddBackward0>)\n",
      "tensor(7.3282, requires_grad=True) tensor(7.3282, requires_grad=True) tensor([6.8054, 8.7920, 5.8338], grad_fn=<AddBackward0>)\n",
      "tensor(7.2307, requires_grad=True) tensor(7.2307, requires_grad=True) tensor([7.0728, 7.4924, 7.3432], grad_fn=<AddBackward0>)\n",
      "tensor(7.1332, requires_grad=True) tensor(7.1332, requires_grad=True) tensor([6.1453, 5.4913, 8.8935], grad_fn=<AddBackward0>)\n",
      "tensor(7.0361, requires_grad=True) tensor(7.0361, requires_grad=True) tensor([4.7823, 8.1959, 6.9514], grad_fn=<AddBackward0>)\n",
      "tensor(6.9408, requires_grad=True) tensor(6.9408, requires_grad=True) tensor([6.2130, 7.2021, 5.6753], grad_fn=<AddBackward0>)\n",
      "tensor(6.8472, requires_grad=True) tensor(6.8472, requires_grad=True) tensor([6.8272, 7.4028, 6.8178], grad_fn=<AddBackward0>)\n",
      "tensor(6.7538, requires_grad=True) tensor(6.7538, requires_grad=True) tensor([5.4376, 6.3728, 7.4030], grad_fn=<AddBackward0>)\n",
      "tensor(6.6618, requires_grad=True) tensor(6.6618, requires_grad=True) tensor([6.1199, 6.6218, 7.9343], grad_fn=<AddBackward0>)\n",
      "tensor(6.5710, requires_grad=True) tensor(6.5710, requires_grad=True) tensor([7.0100, 6.7943, 6.3838], grad_fn=<AddBackward0>)\n",
      "tensor(6.4808, requires_grad=True) tensor(6.4808, requires_grad=True) tensor([6.9509, 6.5979, 7.1572], grad_fn=<AddBackward0>)\n",
      "tensor(6.3905, requires_grad=True) tensor(6.3905, requires_grad=True) tensor([6.5650, 5.2638, 7.0119], grad_fn=<AddBackward0>)\n",
      "tensor(6.3019, requires_grad=True) tensor(6.3019, requires_grad=True) tensor([5.4677, 6.7683, 6.5355], grad_fn=<AddBackward0>)\n",
      "tensor(6.2143, requires_grad=True) tensor(6.2143, requires_grad=True) tensor([5.1180, 5.2517, 5.7806], grad_fn=<AddBackward0>)\n",
      "tensor(6.1285, requires_grad=True) tensor(6.1285, requires_grad=True) tensor([6.0255, 6.5694, 5.7270], grad_fn=<AddBackward0>)\n",
      "tensor(6.0439, requires_grad=True) tensor(6.0439, requires_grad=True) tensor([5.6904, 6.9526, 7.1292], grad_fn=<AddBackward0>)\n",
      "tensor(5.9586, requires_grad=True) tensor(5.9586, requires_grad=True) tensor([5.1917, 4.5250, 6.6629], grad_fn=<AddBackward0>)\n",
      "tensor(5.8757, requires_grad=True) tensor(5.8757, requires_grad=True) tensor([6.8683, 4.9215, 5.1695], grad_fn=<AddBackward0>)\n",
      "tensor(5.7935, requires_grad=True) tensor(5.7935, requires_grad=True) tensor([5.9056, 4.8276, 6.5336], grad_fn=<AddBackward0>)\n",
      "tensor(5.7124, requires_grad=True) tensor(5.7124, requires_grad=True) tensor([7.0763, 6.0725, 6.3822], grad_fn=<AddBackward0>)\n",
      "tensor(5.6306, requires_grad=True) tensor(5.6306, requires_grad=True) tensor([6.2819, 3.6110, 5.5414], grad_fn=<AddBackward0>)\n",
      "tensor(5.5498, requires_grad=True) tensor(5.5498, requires_grad=True) tensor([4.6925, 5.9271, 5.9053], grad_fn=<AddBackward0>)\n",
      "tensor(5.4693, requires_grad=True) tensor(5.4693, requires_grad=True) tensor([6.6264, 5.4111, 5.3087], grad_fn=<AddBackward0>)\n",
      "tensor(5.3899, requires_grad=True) tensor(5.3899, requires_grad=True) tensor([4.5284, 6.3771, 4.4306], grad_fn=<AddBackward0>)\n",
      "tensor(5.3114, requires_grad=True) tensor(5.3114, requires_grad=True) tensor([4.8822, 6.7835, 4.6070], grad_fn=<AddBackward0>)\n",
      "tensor(5.2333, requires_grad=True) tensor(5.2333, requires_grad=True) tensor([6.6826, 4.6868, 4.9297], grad_fn=<AddBackward0>)\n",
      "tensor(5.1552, requires_grad=True) tensor(5.1552, requires_grad=True) tensor([6.2220, 5.7378, 5.0601], grad_fn=<AddBackward0>)\n",
      "tensor(5.0774, requires_grad=True) tensor(5.0774, requires_grad=True) tensor([5.2077, 5.3560, 6.6218], grad_fn=<AddBackward0>)\n",
      "tensor(4.9989, requires_grad=True) tensor(4.9989, requires_grad=True) tensor([5.2157, 6.0467, 6.3680], grad_fn=<AddBackward0>)\n",
      "tensor(4.9193, requires_grad=True) tensor(4.9193, requires_grad=True) tensor([4.0447, 6.8537, 5.7837], grad_fn=<AddBackward0>)\n",
      "tensor(4.8399, requires_grad=True) tensor(4.8399, requires_grad=True) tensor([2.9106, 4.6416, 5.3903], grad_fn=<AddBackward0>)\n",
      "tensor(4.7627, requires_grad=True) tensor(4.7627, requires_grad=True) tensor([4.3884, 4.5728, 3.2372], grad_fn=<AddBackward0>)\n",
      "tensor(4.6875, requires_grad=True) tensor(4.6875, requires_grad=True) tensor([4.4074, 3.8536, 5.8901], grad_fn=<AddBackward0>)\n",
      "tensor(4.6131, requires_grad=True) tensor(4.6131, requires_grad=True) tensor([4.5134, 4.2273, 5.3760], grad_fn=<AddBackward0>)\n",
      "tensor(4.5405, requires_grad=True) tensor(4.5405, requires_grad=True) tensor([4.5910, 4.2152, 5.3980], grad_fn=<AddBackward0>)\n",
      "tensor(4.4697, requires_grad=True) tensor(4.4697, requires_grad=True) tensor([4.1413, 4.8833, 4.3660], grad_fn=<AddBackward0>)\n",
      "tensor(4.4005, requires_grad=True) tensor(4.4005, requires_grad=True) tensor([4.2364, 5.9307, 6.4099], grad_fn=<AddBackward0>)\n",
      "tensor(4.3299, requires_grad=True) tensor(4.3299, requires_grad=True) tensor([4.3881, 3.7885, 4.2181], grad_fn=<AddBackward0>)\n",
      "tensor(4.2620, requires_grad=True) tensor(4.2620, requires_grad=True) tensor([1.9392, 5.6119, 5.2289], grad_fn=<AddBackward0>)\n",
      "tensor(4.1953, requires_grad=True) tensor(4.1953, requires_grad=True) tensor([5.0472, 2.9609, 3.4786], grad_fn=<AddBackward0>)\n",
      "tensor(4.1310, requires_grad=True) tensor(4.1310, requires_grad=True) tensor([4.0267, 2.6191, 4.9765], grad_fn=<AddBackward0>)\n",
      "tensor(4.0678, requires_grad=True) tensor(4.0678, requires_grad=True) tensor([3.4246, 2.5079, 4.4738], grad_fn=<AddBackward0>)\n",
      "tensor(4.0072, requires_grad=True) tensor(4.0072, requires_grad=True) tensor([3.9858, 2.7727, 4.8695], grad_fn=<AddBackward0>)\n",
      "tensor(3.9486, requires_grad=True) tensor(3.9486, requires_grad=True) tensor([4.6562, 2.1168, 3.2405], grad_fn=<AddBackward0>)\n",
      "tensor(3.8921, requires_grad=True) tensor(3.8921, requires_grad=True) tensor([3.9175, 3.0617, 1.4718], grad_fn=<AddBackward0>)\n",
      "tensor(3.8382, requires_grad=True) tensor(3.8382, requires_grad=True) tensor([3.4452, 4.5672, 2.2724], grad_fn=<AddBackward0>)\n",
      "tensor(3.7851, requires_grad=True) tensor(3.7851, requires_grad=True) tensor([3.8753, 2.3398, 2.8512], grad_fn=<AddBackward0>)\n",
      "tensor(3.7343, requires_grad=True) tensor(3.7343, requires_grad=True) tensor([4.5907, 6.1224, 4.5956], grad_fn=<AddBackward0>)\n",
      "tensor(3.6805, requires_grad=True) tensor(3.6805, requires_grad=True) tensor([3.2221, 5.1049, 3.7894], grad_fn=<AddBackward0>)\n",
      "tensor(3.6273, requires_grad=True) tensor(3.6273, requires_grad=True) tensor([2.4965, 3.0395, 1.6668], grad_fn=<AddBackward0>)\n",
      "tensor(3.5779, requires_grad=True) tensor(3.5779, requires_grad=True) tensor([3.4621, 3.5453, 4.8010], grad_fn=<AddBackward0>)\n",
      "tensor(3.5267, requires_grad=True) tensor(3.5267, requires_grad=True) tensor([3.1403, 3.5718, 3.1730], grad_fn=<AddBackward0>)\n",
      "tensor(3.4767, requires_grad=True) tensor(3.4767, requires_grad=True) tensor([3.2014, 1.7532, 3.1088], grad_fn=<AddBackward0>)\n",
      "tensor(3.4296, requires_grad=True) tensor(3.4296, requires_grad=True) tensor([3.3701, 2.9791, 4.4971], grad_fn=<AddBackward0>)\n",
      "tensor(3.3824, requires_grad=True) tensor(3.3824, requires_grad=True) tensor([4.3235, 1.5794, 2.6127], grad_fn=<AddBackward0>)\n",
      "tensor(3.3358, requires_grad=True) tensor(3.3358, requires_grad=True) tensor([2.5298, 2.6282, 4.3232], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2894, requires_grad=True) tensor(3.2894, requires_grad=True) tensor([2.5061, 2.9386, 3.6717], grad_fn=<AddBackward0>)\n",
      "tensor(3.2447, requires_grad=True) tensor(3.2447, requires_grad=True) tensor([2.7557, 4.0397, 3.6361], grad_fn=<AddBackward0>)\n",
      "tensor(3.1991, requires_grad=True) tensor(3.1991, requires_grad=True) tensor([1.9799, 4.2611, 3.8760], grad_fn=<AddBackward0>)\n",
      "tensor(3.1524, requires_grad=True) tensor(3.1524, requires_grad=True) tensor([2.5879, 2.8925, 3.9470], grad_fn=<AddBackward0>)\n",
      "tensor(3.1065, requires_grad=True) tensor(3.1065, requires_grad=True) tensor([2.4013, 6.3705, 4.1411], grad_fn=<AddBackward0>)\n",
      "tensor(3.0579, requires_grad=True) tensor(3.0579, requires_grad=True) tensor([0.9394, 1.7866, 4.4502], grad_fn=<AddBackward0>)\n",
      "tensor(3.0130, requires_grad=True) tensor(3.0130, requires_grad=True) tensor([3.5117, 2.4233, 3.1102], grad_fn=<AddBackward0>)\n",
      "tensor(2.9676, requires_grad=True) tensor(2.9676, requires_grad=True) tensor([2.0787, 3.1578, 4.0806], grad_fn=<AddBackward0>)\n",
      "tensor(2.9233, requires_grad=True) tensor(2.9233, requires_grad=True) tensor([1.3334, 3.8641, 1.8291], grad_fn=<AddBackward0>)\n",
      "tensor(2.8806, requires_grad=True) tensor(2.8806, requires_grad=True) tensor([1.4007, 2.9094, 3.4659], grad_fn=<AddBackward0>)\n",
      "tensor(2.8397, requires_grad=True) tensor(2.8397, requires_grad=True) tensor([3.7324, 3.9974, 3.0137], grad_fn=<AddBackward0>)\n",
      "tensor(2.7973, requires_grad=True) tensor(2.7973, requires_grad=True) tensor([3.8388, 1.0942, 1.5277], grad_fn=<AddBackward0>)\n",
      "tensor(2.7580, requires_grad=True) tensor(2.7580, requires_grad=True) tensor([1.9635, 3.1664, 3.4338], grad_fn=<AddBackward0>)\n",
      "tensor(2.7198, requires_grad=True) tensor(2.7198, requires_grad=True) tensor([2.2540, 2.2938, 1.8588], grad_fn=<AddBackward0>)\n",
      "tensor(2.6838, requires_grad=True) tensor(2.6838, requires_grad=True) tensor([3.9627, 2.2554, 3.4594], grad_fn=<AddBackward0>)\n",
      "tensor(2.6446, requires_grad=True) tensor(2.6446, requires_grad=True) tensor([3.0897, 3.3137, 2.6555], grad_fn=<AddBackward0>)\n",
      "tensor(2.6056, requires_grad=True) tensor(2.6056, requires_grad=True) tensor([2.1102, 1.9500, 3.0729], grad_fn=<AddBackward0>)\n",
      "tensor(2.5683, requires_grad=True) tensor(2.5683, requires_grad=True) tensor([1.5169, 2.6776, 2.4642], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses, model_traces, guide_traces, x1_locs, x2_locs = train(model, guide, data=[args]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4088f873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyro.poutine.trace_struct.Trace at 0x136776590>,\n",
       " <pyro.poutine.trace_struct.Trace at 0x136776bd0>,\n",
       " <pyro.poutine.trace_struct.Trace at 0x1367a1510>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_traces[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f574c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = guide_traces[0].nodes['x1']['fn']\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.__self__._params, fn.__self__._constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_traces[0].nodes['x1_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3afb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'param',\n",
       "  'name': 'x1_loc',\n",
       "  'fn': <bound method ParamStoreDict.get_param of <pyro.params.param_store.ParamStoreDict object at 0x136776e90>>,\n",
       "  'is_observed': False,\n",
       "  'args': ('x1_loc', tensor(10.)),\n",
       "  'kwargs': {'constraint': Real(), 'event_dim': None},\n",
       "  'value': tensor(2.5326, requires_grad=True),\n",
       "  'scale': 1.0,\n",
       "  'mask': None,\n",
       "  'cond_indep_stack': (),\n",
       "  'done': True,\n",
       "  'stop': False,\n",
       "  'continuation': None,\n",
       "  'infer': {}},\n",
       " {'type': 'param',\n",
       "  'name': 'x1_loc',\n",
       "  'fn': <bound method ParamStoreDict.get_param of <pyro.params.param_store.ParamStoreDict object at 0x136776dd0>>,\n",
       "  'is_observed': False,\n",
       "  'args': ('x1_loc', tensor(10.)),\n",
       "  'kwargs': {'constraint': Real(), 'event_dim': None},\n",
       "  'value': tensor(2.5326, requires_grad=True),\n",
       "  'scale': 1.0,\n",
       "  'mask': None,\n",
       "  'cond_indep_stack': (),\n",
       "  'done': True,\n",
       "  'stop': False,\n",
       "  'continuation': None,\n",
       "  'infer': {}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[guide_traces[i].nodes['x1_loc'] for i in [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdecbe75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'sample',\n",
       "  'name': 'x1',\n",
       "  'fn': Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       "  'is_observed': False,\n",
       "  'args': (),\n",
       "  'kwargs': {},\n",
       "  'value': tensor([10.1091,  9.3309,  9.8076], grad_fn=<AddBackward0>),\n",
       "  'infer': {},\n",
       "  'scale': 1.0,\n",
       "  'mask': None,\n",
       "  'cond_indep_stack': (CondIndepStackFrame(name='mini_batch', dim=-1, size=3, counter=0),),\n",
       "  'done': True,\n",
       "  'stop': True,\n",
       "  'continuation': None,\n",
       "  'log_prob_sum': tensor(-3.0051, grad_fn=<SumBackward0>)},\n",
       " {'type': 'sample',\n",
       "  'name': 'x1',\n",
       "  'fn': Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       "  'is_observed': False,\n",
       "  'args': (),\n",
       "  'kwargs': {},\n",
       "  'value': tensor([1.5169, 2.6776, 2.4642], grad_fn=<AddBackward0>),\n",
       "  'infer': {},\n",
       "  'scale': 1.0,\n",
       "  'mask': None,\n",
       "  'cond_indep_stack': (CondIndepStackFrame(name='mini_batch', dim=-1, size=3, counter=0),),\n",
       "  'done': True,\n",
       "  'stop': True,\n",
       "  'continuation': None,\n",
       "  'log_prob_sum': tensor(-3.3209, grad_fn=<SumBackward0>)}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[guide_traces[i].nodes['x1'] for i in [0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_traces[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd966db",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_traces[1].nodes['x1_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_traces[0].nodes['x1_loc']['fn']('x1_loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9348581",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_traces[-1].nodes['x1_loc']['fn']('x1_loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2880b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>),\n",
       " tensor([2.5326, 2.5326, 2.5326], grad_fn=<AsStridedBackward0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[guide_traces[i].nodes['x1']['fn'].loc for i in range(0,100,10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
