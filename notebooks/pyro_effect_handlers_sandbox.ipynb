{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637c1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim.multi import MixedMultiOptimizer\n",
    "from pyro import poutine\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524dabd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.2195, -0.1973,  1.3594]),\n",
       " tensor([0.6021, 0.8084, 0.5671]),\n",
       " tensor([1.0000, 1.1000, 1.2000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(args):\n",
    "  with pyro.plate('mini_batch',args['x3_obs'].shape[0]):\n",
    "    loc_prior = args['loc_prior']\n",
    "    x1 = pyro.sample('x1',dist.Normal(loc_prior,1))\n",
    "    x2 = pyro.sample('x2',dist.Normal(x1,1))\n",
    "    x3 = pyro.sample('x3',dist.Normal(x2,1), obs=args['x3_obs'])\n",
    "  return x1, x2, x3\n",
    "\n",
    "args={}\n",
    "args['loc_prior'] = tensor(1.)\n",
    "args['x3_obs'] = tensor([1., 1.1, 1.2])\n",
    "\n",
    "model(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f859f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyro.poutine.trace_struct.Trace at 0x105510050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = pyro.poutine.trace(model).get_trace(args)\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f60a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = pyro.poutine.trace_logger(model).get_trace(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a18bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = pyro.poutine.trace_logger(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b499ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tl.get_trace(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1679fda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(10., requires_grad=True), tensor(10., requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "def guide(args):\n",
    "  x1_loc = pyro.param('x1_loc',tensor(10.))\n",
    "  x2_loc = pyro.param('x2_loc',tensor(10.))\n",
    "  with pyro.plate('mini_batch',args['x3_obs'].shape[0]):\n",
    "    x1 = pyro.sample('x1',dist.Normal(x1_loc,1))\n",
    "    x2 = pyro.sample('x2',dist.Normal(x2_loc,1))\n",
    "\n",
    "g_trace = pyro.poutine.trace(guide).get_trace(args)\n",
    "params = [g_trace.nodes[name][\"value\"].unconstrained() for name in g_trace.param_nodes] # value changes during training. need to recompute g_trace\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c98da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_trace(model,guide,args,model_condition_data={}):\n",
    "  \"\"\"\n",
    "  TODO: guide_traces['x1/x2_loc'] history not stored. only most recent value\n",
    "    also not stored in guide_traces[0].nodes['x1']['fn'].loc\n",
    "  \"\"\"\n",
    "  # http://pyro.ai/examples/effect_handlers.html#Example:-Variational-inference-with-a-Monte-Carlo-ELBO\n",
    "  conditioned_model = poutine.condition(model, data=model_condition_data) # https://docs.pyro.ai/en/stable/poutine.html#module-pyro.poutine.handlers\n",
    "  guide_trace = poutine.trace_logger(guide).get_trace(args)\n",
    "  model_trace = poutine.trace_logger(\n",
    "          poutine.replay(conditioned_model, trace=guide_trace)\n",
    "      ).get_trace(args)\n",
    "  p = model_trace.log_prob_sum() \n",
    "  q = guide_trace.log_prob_sum()\n",
    "  elbo = p - q\n",
    "  elbo_loss = -elbo\n",
    "  return elbo_loss, model_trace, guide_trace\n",
    "\n",
    "def train(model, guide, data):\n",
    "  adam = pyro.optim.Adam({'lr': 0.1})\n",
    "  sgd = pyro.optim.SGD({'lr': 0.01})\n",
    "  optim = MixedMultiOptimizer([(['x1_loc'], adam), (['x2_loc'], sgd)])\n",
    "  losses = []\n",
    "  model_traces = []\n",
    "  guide_traces = []\n",
    "  x1_locs = []\n",
    "  x2_locs = []\n",
    "  for batch in data:\n",
    "      # this poutine.trace will record all of the parameters that appear in the model and guide\n",
    "      # during the execution of monte_carlo_elbo\n",
    "      with poutine.trace() as param_capture:\n",
    "          # we use poutine.block here so that only parameters appear in the trace above\n",
    "          with poutine.block(hide_fn=lambda node: node[\"type\"] != \"param\"):\n",
    "              elbo_loss, model_trace, guide_trace = loss_and_trace(model, guide, batch, model_condition_data={})\n",
    "              losses.append(elbo_loss.item())\n",
    "              model_traces.append(model_trace)\n",
    "              guide_traces.append(guide_trace)\n",
    "              x1_locs.append(pyro.param('x1_loc').item())\n",
    "              x2_locs.append(pyro.param('x2_loc').item())\n",
    "      params = {name: site['value'].unconstrained()\n",
    "        for name, site in param_capture.trace.nodes.items()\n",
    "        if site['type'] == 'param'}\n",
    "      optim.step(elbo_loss, params)\n",
    "  return losses, model_traces, guide_traces, x1_locs, x2_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df33929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, model_traces, guide_traces, x1_locs, x2_locs = train(model, guide, data=[args]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4088f873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyro.poutine.trace_struct.Trace at 0x105530c10>,\n",
       " <pyro.poutine.trace_struct.Trace at 0x12e20f2d0>,\n",
       " <pyro.poutine.trace_struct.Trace at 0x10553c1d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_traces[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3afb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_INPUT',\n",
       "              {'name': '_INPUT',\n",
       "               'type': 'args',\n",
       "               'args': ({'loc_prior': tensor(1.),\n",
       "                 'x3_obs': tensor([1.0000, 1.1000, 1.2000])},),\n",
       "               'kwargs': {}}),\n",
       "             ('x1_loc',\n",
       "              {'type': 'param',\n",
       "               'name': 'x1_loc',\n",
       "               'fn': <bound method ParamStoreDict.get_param of <pyro.params.param_store.ParamStoreDict object at 0x12e39b850>>,\n",
       "               'is_observed': False,\n",
       "               'args': ('x1_loc', tensor(10.)),\n",
       "               'kwargs': {'constraint': Real(), 'event_dim': None},\n",
       "               'value': tensor(2.5163, requires_grad=True),\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None,\n",
       "               'infer': {}}),\n",
       "             ('x2_loc',\n",
       "              {'type': 'param',\n",
       "               'name': 'x2_loc',\n",
       "               'fn': <bound method ParamStoreDict.get_param of <pyro.params.param_store.ParamStoreDict object at 0x12e39b850>>,\n",
       "               'is_observed': False,\n",
       "               'args': ('x2_loc', tensor(10.)),\n",
       "               'kwargs': {'constraint': Real(), 'event_dim': None},\n",
       "               'value': tensor(2.2310, requires_grad=True),\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None,\n",
       "               'infer': {}}),\n",
       "             ('mini_batch',\n",
       "              {'type': 'sample',\n",
       "               'name': 'mini_batch',\n",
       "               'fn': <pyro.poutine.subsample_messenger._Subsample at 0x12e3c0710>,\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([0, 1, 2]),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': True,\n",
       "               'continuation': None,\n",
       "               'log_prob_sum': tensor(0.)}),\n",
       "             ('x1',\n",
       "              {'type': 'sample',\n",
       "               'name': 'x1',\n",
       "               'fn': Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([9.1783, 9.2719, 9.9291], grad_fn=<AddBackward0>),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (CondIndepStackFrame(name='mini_batch', dim=-1, size=3, counter=0),),\n",
       "               'done': True,\n",
       "               'stop': True,\n",
       "               'continuation': None,\n",
       "               'log_prob_sum': tensor(-3.3620, grad_fn=<SumBackward0>)}),\n",
       "             ('x2',\n",
       "              {'type': 'sample',\n",
       "               'name': 'x2',\n",
       "               'fn': Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([10.5038, 10.6013, 10.3552], grad_fn=<AddBackward0>),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (CondIndepStackFrame(name='mini_batch', dim=-1, size=3, counter=0),),\n",
       "               'done': True,\n",
       "               'stop': True,\n",
       "               'continuation': None,\n",
       "               'log_prob_sum': tensor(-3.1276, grad_fn=<SumBackward0>)}),\n",
       "             ('_RETURN',\n",
       "              {'name': '_RETURN', 'type': 'return', 'value': None})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_traces[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211b1c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5163)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_traces[0].nodes['x1_loc']['fn']('x1_loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9348581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5163)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_traces[-1].nodes['x1_loc']['fn']('x1_loc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
